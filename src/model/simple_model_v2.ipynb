{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "376cd412-3786-4fac-9f19-815de94ceeb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm in /opt/anaconda3/lib/python3.11/site-packages (4.6.0)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /opt/anaconda3/lib/python3.11/site-packages (from lightgbm) (1.26.4)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.11/site-packages (from lightgbm) (1.11.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042cb4cd-11bc-42f0-bb8b-1a59c421d827",
   "metadata": {},
   "source": [
    "## 2차"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce36c960-26fd-424a-9169-cd75f908546d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22eab631b9154473be262e17ac103514",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fitting encoders:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000758 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3285\n",
      "[LightGBM] [Info] Number of data points in the train set: 2206, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's multi_logloss: 0.874292\tvalid_1's multi_logloss: 1.02676\n",
      "[20]\ttraining's multi_logloss: 0.598673\tvalid_1's multi_logloss: 0.867784\n",
      "[30]\ttraining's multi_logloss: 0.429721\tvalid_1's multi_logloss: 0.781753\n",
      "[40]\ttraining's multi_logloss: 0.321088\tvalid_1's multi_logloss: 0.726497\n",
      "[50]\ttraining's multi_logloss: 0.246436\tvalid_1's multi_logloss: 0.680916\n",
      "[60]\ttraining's multi_logloss: 0.192174\tvalid_1's multi_logloss: 0.656108\n",
      "[70]\ttraining's multi_logloss: 0.152905\tvalid_1's multi_logloss: 0.637044\n",
      "[80]\ttraining's multi_logloss: 0.123727\tvalid_1's multi_logloss: 0.623793\n",
      "[90]\ttraining's multi_logloss: 0.100971\tvalid_1's multi_logloss: 0.617808\n",
      "[100]\ttraining's multi_logloss: 0.0837463\tvalid_1's multi_logloss: 0.613378\n",
      "[110]\ttraining's multi_logloss: 0.0693916\tvalid_1's multi_logloss: 0.617877\n",
      "Early stopping, best iteration is:\n",
      "[102]\ttraining's multi_logloss: 0.0807225\tvalid_1's multi_logloss: 0.613145\n",
      "\n",
      "▶ 테스트 세트 예측 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/call-features/lib/python3.9/site-packages/numpy/_core/fromnumeric.py:57: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbf88ea09d9240d0857b700ca8597372",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "LGBM Predict (test):   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== LightGBM Test ===\n",
      "Accuracy: 0.7932489451476793\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          만족       0.89      0.89      0.89       393\n",
      "          미흡       0.22      0.11      0.14        19\n",
      "    추가 상담 필요       0.34      0.45      0.39        53\n",
      "       해결 불가       0.00      0.00      0.00         9\n",
      "\n",
      "    accuracy                           0.79       474\n",
      "   macro avg       0.36      0.36      0.36       474\n",
      "weighted avg       0.79      0.79      0.79       474\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd, numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from lightgbm import LGBMClassifier, early_stopping, log_evaluation\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# 1) 데이터 로드 -----------------------------------------------\n",
    "train = pd.read_csv('dataset/train.csv', encoding='utf-8-sig')\n",
    "val   = pd.read_csv('dataset/val.csv',   encoding='utf-8-sig')\n",
    "test  = pd.read_csv('dataset/test.csv',  encoding='utf-8-sig')\n",
    "\n",
    "# 2) 상담 결과(target) 인코딩 -----------------------------------\n",
    "# train/val/test 전체의 레이블을 모아 한 번에 fit\n",
    "all_targets = pd.concat([\n",
    "    train['result_label'],\n",
    "    val  ['result_label'],\n",
    "    test ['result_label']\n",
    "]).astype(str)\n",
    "le_result = LabelEncoder().fit(all_targets)\n",
    "\n",
    "# 각 DataFrame 에 숫자형 레이블 컬럼 추가\n",
    "for df in (train, val, test):\n",
    "    df['label_id'] = le_result.transform(df['result_label'].astype(str))\n",
    "\n",
    "# 3) 기타 범주형 피처 인코딩 ------------------------------------\n",
    "categorical_cols = ['sent_label', 'mid_category', 'content_category', 'rec_place']\n",
    "le_cat = {}\n",
    "for col in tqdm(categorical_cols, desc='Fitting encoders'):\n",
    "    # train/val/test 전체 unique 값을 fit\n",
    "    all_vals = pd.concat([train[col], val[col], test[col]]).astype(str)\n",
    "    le = LabelEncoder().fit(all_vals)\n",
    "    le_cat[col] = le\n",
    "    # transform\n",
    "    for df in (train, val, test):\n",
    "        df[f'{col}_id'] = le.transform(df[col].astype(str))\n",
    "\n",
    "# 4) 피처 컬럼 구성 ---------------------------------------------\n",
    "# 모델에 사용하지 않을 컬럼(문자열, 리스트, ID 등) 정의\n",
    "drop_cols = (\n",
    "    ['session_id', 'result_label', 'label_id', 'asr_segments', 'top_nouns']\n",
    "    + categorical_cols\n",
    ")\n",
    "feature_cols = [c for c in train.columns if c not in drop_cols]\n",
    "\n",
    "# 5) 학습/검증/테스트 세트 분리 -----------------------------------\n",
    "X_train, y_train = train[feature_cols], train['label_id']\n",
    "X_val,   y_val   = val  [feature_cols], val  ['label_id']\n",
    "X_test,  y_test  = test [feature_cols], test ['label_id']\n",
    "\n",
    "# 6) 클래스 가중치 계산\n",
    "classes = np.unique(y_train)\n",
    "weights = compute_class_weight('balanced', classes=classes, y=y_train)\n",
    "class_weight = dict(zip(classes, weights))\n",
    "\n",
    "# 7) LightGBM 학습 (가중치 적용)\n",
    "model = LGBMClassifier(\n",
    "    objective='multiclass',\n",
    "    num_class=len(le_result.classes_),\n",
    "    n_estimators=200,\n",
    "    learning_rate=0.05,\n",
    "    class_weight=class_weight,    # ← 여기\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_train, y_train), (X_val, y_val)],\n",
    "    eval_metric='multi_logloss',\n",
    "    callbacks=[early_stopping(stopping_rounds=10), log_evaluation(period=10)]\n",
    ")\n",
    "\n",
    "# 8) 테스트 세트 예측 및 평가 ------------------------------------\n",
    "print(\"\\n▶ 테스트 세트 예측 중...\")\n",
    "y_pred_test = []\n",
    "for chunk in tqdm(np.array_split(X_test, 10), desc='LGBM Predict (test)'):\n",
    "    proba = model.predict_proba(chunk)\n",
    "    y_pred_test.extend(np.argmax(proba, axis=1))\n",
    "\n",
    "print(\"\\n=== LightGBM Test ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_test))\n",
    "print(classification_report(y_test, y_pred_test, target_names=le_result.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ad4a3d-fb81-40c5-af9e-6b5034e558a5",
   "metadata": {},
   "source": [
    "## 3차 텍스트 임베딩 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1459104-5890-4264-a341-cd02e9cb40ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/anaconda3/envs/call-features/lib/python3.9/site-packages (4.51.3)\n",
      "Requirement already satisfied: torch in /opt/anaconda3/envs/call-features/lib/python3.9/site-packages (2.5.1)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/envs/call-features/lib/python3.9/site-packages (from transformers) (3.17.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /opt/anaconda3/envs/call-features/lib/python3.9/site-packages (from transformers) (0.31.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/envs/call-features/lib/python3.9/site-packages (from transformers) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/envs/call-features/lib/python3.9/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/envs/call-features/lib/python3.9/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/envs/call-features/lib/python3.9/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/envs/call-features/lib/python3.9/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/anaconda3/envs/call-features/lib/python3.9/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/anaconda3/envs/call-features/lib/python3.9/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/anaconda3/envs/call-features/lib/python3.9/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/envs/call-features/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/envs/call-features/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /opt/anaconda3/envs/call-features/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.0)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/envs/call-features/lib/python3.9/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/envs/call-features/lib/python3.9/site-packages (from torch) (3.1.6)\n",
      "Collecting sympy==1.13.1 (from torch)\n",
      "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/envs/call-features/lib/python3.9/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/envs/call-features/lib/python3.9/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/envs/call-features/lib/python3.9/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/call-features/lib/python3.9/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/call-features/lib/python3.9/site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/call-features/lib/python3.9/site-packages (from requests->transformers) (2025.4.26)\n",
      "Downloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "Installing collected packages: sympy\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.13.3\n",
      "    Uninstalling sympy-1.13.3:\n",
      "      Successfully uninstalled sympy-1.13.3\n",
      "Successfully installed sympy-1.13.1\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8758d946-6864-46bd-9894-20a6b9806c45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9541791fc5ae40199627827e8e57940b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1. JSON → DataFrame:   0%|          | 0/3533 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d4e6ec03b4a4d66922d6337946af98b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "2. TFIDF fit:   0%|          | 0/2119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa9da01fa65f49a0a05bd628cc1aec9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "3. TFIDF val:   0%|          | 0/707 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86a4475949b847748db61623cc25436d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "4. TFIDF test:   0%|          | 0/707 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ 사용할 메타 피처: ['speech_count', '고객_emo_1_star_score', '고객_emo_2_star_score', '고객_emo_3_star_score', '고객_emo_4_star_score', '고객_emo_5_star_score', '고객_sent_score', '상담사_emo_1_star_score', '상담사_emo_2_star_score', '상담사_emo_3_star_score', '상담사_emo_4_star_score', '상담사_emo_5_star_score', '상담사_sent_score', 'consulting_category_id']\n",
      "▶ 10. LightGBM 학습 중…\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032928 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 143226\n",
      "[LightGBM] [Info] Number of data points in the train set: 2119, number of used features: 4136\n",
      "[LightGBM] [Info] Start training from score -0.189045\n",
      "[LightGBM] [Info] Start training from score -3.147840\n",
      "[LightGBM] [Info] Start training from score -2.203378\n",
      "[LightGBM] [Info] Start training from score -3.969820\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[20]\ttraining's multi_logloss: 0.201046\tvalid_1's multi_logloss: 0.477044\n",
      "[40]\ttraining's multi_logloss: 0.0825988\tvalid_1's multi_logloss: 0.465953\n",
      "Early stopping, best iteration is:\n",
      "[30]\ttraining's multi_logloss: 0.126918\tvalid_1's multi_logloss: 0.461396\n",
      "\n",
      "--- 검증 세트 평가 ---\n",
      "Accuracy: 0.8529\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          만족       0.86      0.99      0.92       586\n",
      "          미흡       0.00      0.00      0.00        30\n",
      "    추가 상담 필요       0.77      0.29      0.43        78\n",
      "       해결 불가       0.00      0.00      0.00        13\n",
      "\n",
      "    accuracy                           0.85       707\n",
      "   macro avg       0.41      0.32      0.34       707\n",
      "weighted avg       0.79      0.85      0.81       707\n",
      "\n",
      "\n",
      "--- 테스트 세트 평가 ---\n",
      "Accuracy: 0.8571\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          만족       0.86      0.99      0.92       586\n",
      "          미흡       0.00      0.00      0.00        30\n",
      "    추가 상담 필요       0.72      0.33      0.46        78\n",
      "       해결 불가       0.00      0.00      0.00        13\n",
      "\n",
      "    accuracy                           0.86       707\n",
      "   macro avg       0.40      0.33      0.34       707\n",
      "weighted avg       0.80      0.86      0.82       707\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# 형태소 분석기\n",
    "from konlpy.tag import Okt\n",
    "\n",
    "# TF–IDF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# 인코딩 / 분할\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# LightGBM\n",
    "from lightgbm import LGBMClassifier, early_stopping, log_evaluation\n",
    "\n",
    "# 평가\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 1) JSON 파일 순회 → 상담 원문 + 주제 메타 DataFrame 생성\n",
    "# -----------------------------------------------------------------------------\n",
    "FINAL_DIR = 'json_merge/integration_data_v3'  # 실제 폴더명으로 수정\n",
    "rows = []\n",
    "for fp in tqdm(glob.glob(os.path.join(FINAL_DIR, '*.json')), desc='1. JSON → DataFrame'):\n",
    "    with open(fp, 'r', encoding='utf-8') as f:\n",
    "        j = json.load(f)\n",
    "    sid = str(j.get('session_id') or os.path.splitext(os.path.basename(fp))[0])\n",
    "\n",
    "    # 두 가지 포맷 모두 처리\n",
    "    if 'classification' in j:\n",
    "        meta     = j['classification']\n",
    "        content  = meta.get('consulting_content', '')\n",
    "        category = meta.get('consulting_category', '')\n",
    "    else:\n",
    "        content  = j.get('consulting_content', '')\n",
    "        category = j.get('consulting_category', '')\n",
    "\n",
    "    rows.append({\n",
    "        'session_id': sid,\n",
    "        'consulting_content': content,\n",
    "        'consulting_category': category\n",
    "    })\n",
    "df_meta = pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 2) 기존 텍스트 특성 CSV 불러오기\n",
    "# -----------------------------------------------------------------------------\n",
    "df_feats = pd.read_csv(\n",
    "    'column_extraction/text_features_all_v3.csv',  # 실제 파일명으로 수정\n",
    "    dtype={'session_id': str},\n",
    "    encoding='utf-8-sig'\n",
    ")\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 3) 레이블 CSV 불러오기 (session_id, result_label)\n",
    "# -----------------------------------------------------------------------------\n",
    "df_labels = pd.read_csv(\n",
    "    'column_extraction/preprocessing/session_labels.csv',  # 실제 파일명으로 수정\n",
    "    dtype={'session_id': str},\n",
    "    encoding='utf-8-sig'\n",
    ")\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 4) 세 DataFrame을 session_id 기준으로 병합\n",
    "# -----------------------------------------------------------------------------\n",
    "df = (\n",
    "    df_feats\n",
    "      .merge(df_meta,   on='session_id', how='left')\n",
    "      .merge(df_labels, on='session_id', how='inner')\n",
    ")\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 5) 훈련/검증/테스트 데이터 분할 (stratify 유지)\n",
    "# -----------------------------------------------------------------------------\n",
    "train_val, test = train_test_split(\n",
    "    df,\n",
    "    test_size=0.2,\n",
    "    stratify=df['result_label'],\n",
    "    random_state=42\n",
    ")\n",
    "train, val = train_test_split(\n",
    "    train_val,\n",
    "    test_size=0.25,\n",
    "    stratify=train_val['result_label'],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 6) result_label → label_id로 인코딩\n",
    "# -----------------------------------------------------------------------------\n",
    "le = LabelEncoder().fit(train['result_label'])\n",
    "for d in (train, val, test):\n",
    "    d['label_id'] = le.transform(d['result_label'])\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 7) TF–IDF 벡터화 (형태소 명사만 사용) with tqdm\n",
    "# -----------------------------------------------------------------------------\n",
    "okt = Okt()\n",
    "def noun_tokenizer(text):\n",
    "    return okt.nouns(text)\n",
    "\n",
    "tfidf = TfidfVectorizer(\n",
    "    tokenizer=noun_tokenizer,\n",
    "    max_features=5000,\n",
    "    ngram_range=(1,2),\n",
    "    min_df=5\n",
    ")\n",
    "\n",
    "X_tfidf_train = tfidf.fit_transform(\n",
    "    tqdm(train['consulting_content'], desc='2. TFIDF fit')\n",
    ")\n",
    "X_tfidf_val = tfidf.transform(\n",
    "    tqdm(val['consulting_content'], desc='3. TFIDF val')\n",
    ")\n",
    "X_tfidf_test = tfidf.transform(\n",
    "    tqdm(test['consulting_content'], desc='4. TFIDF test')\n",
    ")\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 8) 메타 피처 준비 (categorical → 숫자 ID)\n",
    "# -----------------------------------------------------------------------------\n",
    "# 8-1) 상담 주제 ID 인코딩\n",
    "le_cat = LabelEncoder().fit(df['consulting_category'].astype(str))\n",
    "for d in (train, val, test):\n",
    "    d['consulting_category_id'] = le_cat.transform(d['consulting_category'].astype(str))\n",
    "\n",
    "# 8-2) 실제로 존재하는 메타컬럼만 골라내기\n",
    "desired_meta_cols = [\n",
    "    'speech_count',\n",
    "    # (기존 emo_* 칼럼이 없으면 skip)\n",
    "    'emo_1_star_score','emo_2_star_score','emo_3_star_score',\n",
    "    'emo_4_star_score','emo_5_star_score','sent_score',\n",
    "    # 고객 prefix 감정\n",
    "    *[f'고객_emo_{i}_star_score' for i in range(1,6)],\n",
    "    '고객_sent_score',\n",
    "    # 상담사 prefix 감정\n",
    "    *[f'상담사_emo_{i}_star_score' for i in range(1,6)],\n",
    "    '상담사_sent_score',\n",
    "    # 분류 ID\n",
    "    'consulting_category_id'\n",
    "]\n",
    "\n",
    "meta_cols = [c for c in desired_meta_cols if c in train.columns]\n",
    "print(\"→ 사용할 메타 피처:\", meta_cols)\n",
    "\n",
    "X_meta_train = train[meta_cols].values\n",
    "X_meta_val   =   val[meta_cols].values\n",
    "X_meta_test  =  test[meta_cols].values\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 9) 최종 feature & label 준비 (TFIDF + 메타)\n",
    "# -----------------------------------------------------------------------------\n",
    "X_train, y_train = (\n",
    "    np.hstack([X_tfidf_train.toarray(), X_meta_train]),\n",
    "    train['label_id']\n",
    ")\n",
    "X_val, y_val = (\n",
    "    np.hstack([X_tfidf_val.toarray(), X_meta_val]),\n",
    "    val['label_id']\n",
    ")\n",
    "X_test, y_test = (\n",
    "    np.hstack([X_tfidf_test.toarray(), X_meta_test]),\n",
    "    test['label_id']\n",
    ")\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 10) LightGBM 베이스라인 학습 (early stopping & 로그)\n",
    "# -----------------------------------------------------------------------------\n",
    "model = LGBMClassifier(\n",
    "    objective='multiclass',\n",
    "    num_class=len(le.classes_),\n",
    "    n_estimators=200,\n",
    "    learning_rate=0.05,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"▶ 10. LightGBM 학습 중…\")\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_train,y_train),(X_val,y_val)],\n",
    "    eval_metric='multi_logloss',\n",
    "    callbacks=[\n",
    "        early_stopping(stopping_rounds=10),\n",
    "        log_evaluation(period=20)\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 11) 검증·테스트 세트 평가\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"\\n--- 검증 세트 평가 ---\")\n",
    "pred_val = model.predict(X_val)\n",
    "print(f\"Accuracy: {accuracy_score(y_val, pred_val):.4f}\")\n",
    "print(classification_report(y_val, pred_val, target_names=le.classes_))\n",
    "\n",
    "print(\"\\n--- 테스트 세트 평가 ---\")\n",
    "pred_test = model.predict(X_test)\n",
    "print(f\"Accuracy: {accuracy_score(y_test, pred_test):.4f}\")\n",
    "print(classification_report(y_test, pred_test, target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21103f6a-9af0-4d8e-bac7-bae6b4596f71",
   "metadata": {},
   "source": [
    "# V2 학습 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2bcb2ad-8731-4e98-918c-90305bbbb882",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6004b72e4a243e89348d68f7279e61e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1. JSON → DataFrame:   0%|          | 0/3533 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39fda6961da548ce8730c3ce2a6c5fe7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "2. TFIDF fit:   0%|          | 0/2119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aba220d62331459985e3370b25de6bdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "3. TFIDF val:   0%|          | 0/707 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e8cce54138d44ed87ca8ac57c4bc772",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "4. TFIDF test:   0%|          | 0/707 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd2fc476e01a42e9b889f2cc0430317b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "5. LabelEncode meta:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ actual train.columns:\n",
      " ['session_id', 'speech_count', 'asr_segments', 'top_nouns', '고객_emo_1_star_score', '고객_emo_2_star_score', '고객_emo_3_star_score', '고객_emo_4_star_score', '고객_emo_5_star_score', '고객_sent_score', '고객_sent_label', '상담사_emo_1_star_score', '상담사_emo_2_star_score', '상담사_emo_3_star_score', '상담사_emo_4_star_score', '상담사_emo_5_star_score', '상담사_sent_score', '상담사_sent_label', 'mid_category', 'content_category', 'rec_place', 'script_phrase_ratio', 'honorific_ratio', 'positive_word_ratio', 'euphonious_word_ratio', 'confirmation_ratio', 'empathy_ratio', 'apology_ratio', 'request_ratio', 'alternative_suggestion_count', 'conflict_flag', 'manual_compliance_ratio', 'consulting_content', 'consulting_category', 'result_label', 'label_id', 'consulting_category_id', 'rec_place_id']\n",
      "→ 사용할 메타 피처: ['speech_count', '고객_emo_1_star_score', '고객_emo_2_star_score', '고객_emo_3_star_score', '고객_emo_4_star_score', '고객_emo_5_star_score', '고객_sent_score', '상담사_emo_1_star_score', '상담사_emo_2_star_score', '상담사_emo_3_star_score', '상담사_emo_4_star_score', '상담사_emo_5_star_score', '상담사_sent_score', 'consulting_category_id', 'rec_place_id']\n",
      "▶ 6. LightGBM 학습 중…\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030460 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 143272\n",
      "[LightGBM] [Info] Number of data points in the train set: 2119, number of used features: 4138\n",
      "[LightGBM] [Info] Start training from score -0.189045\n",
      "[LightGBM] [Info] Start training from score -3.147840\n",
      "[LightGBM] [Info] Start training from score -2.203378\n",
      "[LightGBM] [Info] Start training from score -3.969820\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[20]\ttraining's multi_logloss: 0.200202\tvalid_1's multi_logloss: 0.472263\n",
      "[40]\ttraining's multi_logloss: 0.0824977\tvalid_1's multi_logloss: 0.461241\n",
      "Early stopping, best iteration is:\n",
      "[32]\ttraining's multi_logloss: 0.115896\tvalid_1's multi_logloss: 0.457684\n",
      "\n",
      "--- 검증 세트 평가 ---\n",
      "Accuracy: 0.8571\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          만족       0.86      0.99      0.92       586\n",
      "          미흡       0.00      0.00      0.00        30\n",
      "    추가 상담 필요       0.79      0.33      0.47        78\n",
      "       해결 불가       0.00      0.00      0.00        13\n",
      "\n",
      "    accuracy                           0.86       707\n",
      "   macro avg       0.41      0.33      0.35       707\n",
      "weighted avg       0.80      0.86      0.81       707\n",
      "\n",
      "\n",
      "--- 테스트 세트 평가 ---\n",
      "Accuracy: 0.8614\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          만족       0.87      0.99      0.93       586\n",
      "          미흡       0.00      0.00      0.00        30\n",
      "    추가 상담 필요       0.74      0.37      0.50        78\n",
      "       해결 불가       0.00      0.00      0.00        13\n",
      "\n",
      "    accuracy                           0.86       707\n",
      "   macro avg       0.40      0.34      0.36       707\n",
      "weighted avg       0.80      0.86      0.82       707\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import os, glob, json\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# 1) 형태소 명사 추출용\n",
    "from konlpy.tag import Okt\n",
    "\n",
    "# 2) TF–IDF & 모델링\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from lightgbm import LGBMClassifier\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 1) JSON 파일 순회 → 상담 원문 & 주제 메타 DataFrame 생성\n",
    "# -----------------------------------------------------------------------------\n",
    "FINAL_DIR = 'combination_data'  # 실제 폴더명으로 수정\n",
    "rows = []\n",
    "json_files = glob.glob(os.path.join(FINAL_DIR, '*.json'))\n",
    "\n",
    "for fp in tqdm(json_files, desc='1. JSON → DataFrame'):\n",
    "    with open(fp, 'r', encoding='utf-8') as f:\n",
    "        j = json.load(f)\n",
    "    sid = str(j.get('session_id') or os.path.splitext(os.path.basename(fp))[0])\n",
    "\n",
    "    # 두 가지 포맷 모두 처리\n",
    "    if 'classification' in j:\n",
    "        meta     = j['classification']\n",
    "        content  = meta.get('consulting_content', '')\n",
    "        category = meta.get('consulting_category', '')\n",
    "    else:\n",
    "        content  = j.get('consulting_content', '')\n",
    "        category = j.get('consulting_category', '')\n",
    "\n",
    "    rows.append({\n",
    "        'session_id': sid,\n",
    "        'consulting_content': content,\n",
    "        'consulting_category': category\n",
    "    })\n",
    "\n",
    "df_meta = pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 2) 기존 텍스트 특성 CSV 불러오기\n",
    "# -----------------------------------------------------------------------------\n",
    "df_feats = pd.read_csv(\n",
    "    'output/text_features_all_v3.csv',  # 실제 파일명으로 수정\n",
    "    dtype={'session_id': str},\n",
    "    encoding='utf-8-sig'\n",
    ")\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 3) 레이블 CSV 불러오기 (session_id, result_label)\n",
    "# -----------------------------------------------------------------------------\n",
    "df_labels = pd.read_csv(\n",
    "    'output/session_labels_v3.csv',  # 실제 파일명으로 수정\n",
    "    dtype={'session_id': str},\n",
    "    encoding='utf-8-sig'\n",
    ")\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 4) 세 DataFrame을 session_id 기준으로 병합\n",
    "# -----------------------------------------------------------------------------\n",
    "df = (\n",
    "    df_feats\n",
    "      .merge(df_meta,   on='session_id', how='left')\n",
    "      .merge(df_labels, on='session_id', how='inner')\n",
    ")\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 5) 훈련/검증/테스트 데이터 분할 (stratify 유지)\n",
    "# -----------------------------------------------------------------------------\n",
    "train_val, test = train_test_split(\n",
    "    df,\n",
    "    test_size=0.2,\n",
    "    stratify=df['result_label'],\n",
    "    random_state=42\n",
    ")\n",
    "train, val = train_test_split(\n",
    "    train_val,\n",
    "    test_size=0.25,\n",
    "    stratify=train_val['result_label'],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 6) result_label → label_id로 인코딩\n",
    "# -----------------------------------------------------------------------------\n",
    "le = LabelEncoder().fit(train['result_label'])\n",
    "for d in (train, val, test):\n",
    "    d['label_id'] = le.transform(d['result_label'])\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 7) TF–IDF 벡터화 (형태소 명사만 사용) with tqdm\n",
    "# -----------------------------------------------------------------------------\n",
    "okt = Okt()\n",
    "def noun_tokenizer(text):\n",
    "    return okt.nouns(text)\n",
    "\n",
    "tfidf = TfidfVectorizer(\n",
    "    tokenizer=noun_tokenizer,\n",
    "    max_features=5000,\n",
    "    ngram_range=(1,2),\n",
    "    min_df=5\n",
    ")\n",
    "\n",
    "X_tfidf_train = tfidf.fit_transform(\n",
    "    tqdm(train['consulting_content'], desc='2. TFIDF fit')\n",
    ")\n",
    "X_tfidf_val = tfidf.transform(\n",
    "    tqdm(val['consulting_content'], desc='3. TFIDF val')\n",
    ")\n",
    "X_tfidf_test = tfidf.transform(\n",
    "    tqdm(test['consulting_content'], desc='4. TFIDF test')\n",
    ")\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 8) 메타 피처 준비 (categorical → 숫자 ID 포함)\n",
    "# -----------------------------------------------------------------------------\n",
    "# (8-1) 분류·장소 ID 인코딩\n",
    "for col in tqdm(['consulting_category', 'rec_place'], desc='5. LabelEncode meta'):\n",
    "    le_col = LabelEncoder().fit(df[col].astype(str))\n",
    "    for d in (train, val, test):\n",
    "        d[f'{col}_id'] = le_col.transform(d[col].astype(str))\n",
    "\n",
    "# (8-2) 실제 있는 감정 피처명을 prefix로 반영\n",
    "# → train.columns 확인해서 맞춰주세요\n",
    "print(\"→ actual train.columns:\\n\", train.columns.tolist())\n",
    "\n",
    "desired_meta_cols = [\n",
    "    'speech_count',\n",
    "    # 고객 감정 점수\n",
    "    *[f'고객_emo_{i}_star_score' for i in range(1,6)],\n",
    "    '고객_sent_score',\n",
    "    # 상담사 감정 점수\n",
    "    *[f'상담사_emo_{i}_star_score' for i in range(1,6)],\n",
    "    '상담사_sent_score',\n",
    "    # 분류 ID\n",
    "    'consulting_category_id',\n",
    "    'rec_place_id'\n",
    "]\n",
    "\n",
    "# 실제 train 에 있는 것만 골라냅니다\n",
    "meta_cols = [c for c in desired_meta_cols if c in train.columns]\n",
    "print(\"→ 사용할 메타 피처:\", meta_cols)\n",
    "\n",
    "# numpy array 로 변환\n",
    "X_meta_train = train[meta_cols].values\n",
    "X_meta_val   =   val[meta_cols].values\n",
    "X_meta_test  =  test[meta_cols].values\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 9) 최종 feature & label 준비 (TFIDF + 메타)\n",
    "# -----------------------------------------------------------------------------\n",
    "X_train, y_train = (\n",
    "    np.hstack([X_tfidf_train.toarray(), X_meta_train]),\n",
    "    train['label_id']\n",
    ")\n",
    "X_val, y_val = (\n",
    "    np.hstack([X_tfidf_val.toarray(), X_meta_val]),\n",
    "    val['label_id']\n",
    ")\n",
    "X_test, y_test = (\n",
    "    np.hstack([X_tfidf_test.toarray(), X_meta_test]),\n",
    "    test['label_id']\n",
    ")\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 10) LightGBM 베이스라인 학습 (early stopping & 로그)\n",
    "# -----------------------------------------------------------------------------\n",
    "model = LGBMClassifier(\n",
    "    objective='multiclass',\n",
    "    num_class=len(le.classes_),\n",
    "    n_estimators=200,\n",
    "    learning_rate=0.05,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"▶ 6. LightGBM 학습 중…\")\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_train, y_train), (X_val, y_val)],\n",
    "    eval_metric='multi_logloss',\n",
    "    callbacks=[\n",
    "        lgb.early_stopping(stopping_rounds=10),\n",
    "        lgb.log_evaluation(period=20)\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 11) 검증·테스트 세트 평가\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"\\n--- 검증 세트 평가 ---\")\n",
    "pred_val = model.predict(X_val)\n",
    "print(f\"Accuracy: {accuracy_score(y_val, pred_val):.4f}\")\n",
    "print(classification_report(y_val, pred_val, target_names=le.classes_))\n",
    "\n",
    "print(\"\\n--- 테스트 세트 평가 ---\")\n",
    "pred_test = model.predict(X_test)\n",
    "print(f\"Accuracy: {accuracy_score(y_test, pred_test):.4f}\")\n",
    "print(classification_report(y_test, pred_test, target_names=le.classes_))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
