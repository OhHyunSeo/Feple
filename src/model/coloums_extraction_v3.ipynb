{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22c92fe0-08e8-44d9-bbb4-a36fd4f1e728",
   "metadata": {},
   "source": [
    "## 텍스트 기반 특성 추출 - 샘플 버전"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b1e4cb8-20cc-44d1-b578-721ed0f08afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/anaconda3/lib/python3.11/site-packages (4.51.3)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.11/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /opt/anaconda3/lib/python3.11/site-packages (from transformers) (0.30.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/lib/python3.11/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.11/site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.11/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/lib/python3.11/site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.11/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/anaconda3/lib/python3.11/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/anaconda3/lib/python3.11/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/anaconda3/lib/python3.11/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.11/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.11/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.11/site-packages (from requests->transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.11/site-packages (from requests->transformers) (2025.1.31)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23969e2f-0d45-4c78-a280-9e8d57791107",
   "metadata": {},
   "source": [
    "## json_merge/integration_data 기반으로 데이터셋 제작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5295f2ea-2be7-48bb-80b5-fdd33916a677",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Processing all sessions: 100%|████████████████| 379/379 [04:29<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 모든 세션 처리 완료, CSV → output/text_features_all.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import re\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from konlpy.tag import Okt\n",
    "from transformers import pipeline\n",
    "\n",
    "# ——— 세팅 ———\n",
    "okt = Okt()\n",
    "sentiment = pipeline(\n",
    "    'sentiment-analysis',\n",
    "    model='nlptown/bert-base-multilingual-uncased-sentiment',\n",
    "    top_k=None\n",
    ")\n",
    "\n",
    "# 키워드 사전 (예시 — 실제 프로젝트에 맞게 확장하세요)\n",
    "script_phrases       = [\"안녕하세요\", \"감사합니다\", \"반갑습니다\"]\n",
    "honorific_endings    = [\"습니다\", \"세요\", \"니다\"]\n",
    "positive_words       = [\"좋다\", \"만족\", \"행복\", \"감사\"]\n",
    "euphonious_words     = [\"해주\", \"드리\"]\n",
    "confirmation_phrases = [\"확인\", \"맞으신\", \"괜찮을까요\"]\n",
    "empathy_phrases      = [\"이해합니다\", \"공감\"]\n",
    "apology_phrases      = [\"죄송\", \"미안\"]\n",
    "request_phrases      = [\"부탁\", \"요청\"]\n",
    "alternative_phrases  = [\"하실 수 있습니다\", \"제안합니다\", \"추천드립니다\"]\n",
    "conflict_words       = [\"아닙니다\", \"불가\", \"불편\"]\n",
    "prohibit_words       = [\"욕설1\", \"욕설2\"]\n",
    "\n",
    "def split_sentences(text):\n",
    "    return re.split(r'(?<=[\\.!\\?])\\s+', text)\n",
    "\n",
    "def extract_text_features(record):\n",
    "    content = record['consulting_content']\n",
    "    # 1) ASR 세그먼트 & 발화 수\n",
    "    segments = []\n",
    "    for line in content.split('\\n'):\n",
    "        m = re.match(r'^(상담사|고객):\\s*(.+)', line)\n",
    "        if m:\n",
    "            segments.append({'speaker': m.group(1), 'text': m.group(2)})\n",
    "    speech_count = len(segments)\n",
    "    # 2) top_nouns\n",
    "    all_nouns = []\n",
    "    for seg in segments:\n",
    "        all_nouns += okt.nouns(seg['text'])\n",
    "    top_nouns = [w for w,_ in Counter(all_nouns).most_common(10)]\n",
    "    # 3) 감정 분석 (문장별 평균)\n",
    "    agg = Counter({i:0.0 for i in range(1,6)})\n",
    "    n_sents = 0\n",
    "    for sent in split_sentences(content):\n",
    "        if not sent.strip(): continue\n",
    "        scores = sentiment(sent)[0]\n",
    "        for d in scores:\n",
    "            star = int(d['label'][0])\n",
    "            agg[star] += d['score']\n",
    "        n_sents += 1\n",
    "    emo = {f'emo_{i}_star_score': (agg[i]/n_sents if n_sents else 0.0) for i in range(1,6)}\n",
    "    sent_score = sum(i * emo[f'emo_{i}_star_score'] for i in range(1,6))\n",
    "    if   sent_score >= 3.5: sent_label = \"긍정\"\n",
    "    elif sent_score >= 2.5: sent_label = \"중립\"\n",
    "    else:                  sent_label = \"부정\"\n",
    "    # 4) 분류: 상담 주제 / 상담 내용\n",
    "    mid_category = None\n",
    "    content_category = None\n",
    "    for inst in record.get('instructions', []):\n",
    "        items = inst.get('data', [inst])\n",
    "        for d in items:\n",
    "            if d.get('task_category') == '상담 주제':\n",
    "                mid_category = d.get('output')\n",
    "            elif d.get('task_category') == '상담 내용':\n",
    "                content_category = d.get('output')\n",
    "    # 5) 대화 장소\n",
    "    pm = re.search(r'(\\w+(센터|매장|지점))', content)\n",
    "    rec_place = pm.group(1) if pm else None\n",
    "    # 6) 비율/카운트 헬퍼\n",
    "    def ratio(keys):\n",
    "        tot = len(content.split())\n",
    "        return sum(content.count(k) for k in keys) / tot if tot else 0\n",
    "    def count(keys):\n",
    "        return sum(content.count(k) for k in keys)\n",
    "    # 7) 기타 지표 결합\n",
    "    features = {\n",
    "        'session_id':                   record['session_id'],\n",
    "        'speech_count':                 speech_count,\n",
    "        'asr_segments':                 segments,\n",
    "        'top_nouns':                    ','.join(top_nouns),\n",
    "        **emo,\n",
    "        'sent_score':                   sent_score,\n",
    "        'sent_label':                   sent_label,\n",
    "        'mid_category':                 mid_category,\n",
    "        'content_category':             content_category,\n",
    "        'rec_place':                    rec_place,\n",
    "        'script_phrase_ratio':          ratio(script_phrases),\n",
    "        'honorific_ratio':              ratio(honorific_endings),\n",
    "        'positive_word_ratio':          ratio(positive_words),\n",
    "        'euphonious_word_ratio':        ratio(euphonious_words),\n",
    "        'confirmation_ratio':           ratio(confirmation_phrases),\n",
    "        'empathy_ratio':                ratio(empathy_phrases),\n",
    "        'apology_ratio':                ratio(apology_phrases),\n",
    "        'request_ratio':                ratio(request_phrases),\n",
    "        'alternative_suggestion_count': count(alternative_phrases),\n",
    "        'conflict_flag':                int(any(w in content for w in conflict_words)),\n",
    "        'manual_compliance_ratio':      1 - (count(prohibit_words) / max(1, speech_count))\n",
    "    }\n",
    "    return features\n",
    "\n",
    "# ——— output_final 내 모든 JSON 파일 순회 & 처리 ———\n",
    "all_files = glob.glob('output_final_2/**/*.json', recursive=True)\n",
    "rows = []\n",
    "for fp in tqdm(all_files, desc='Processing all sessions'):\n",
    "    with open(fp, 'r', encoding='utf-8') as f:\n",
    "        rec = json.load(f)\n",
    "    rows.append(extract_text_features(rec))\n",
    "\n",
    "# ——— DataFrame 생성 및 CSV 저장 ———\n",
    "df = pd.DataFrame(rows)\n",
    "os.makedirs('output_columns_2', exist_ok=True)\n",
    "df.to_csv('output_columns_2/text_features_all.csv', index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(f'✅ 모든 세션 처리 완료, CSV → output/text_features_all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "749e42ec-5c10-4275-9333-f4f0d2333b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 모든 세션 처리 완료, CSV → output/text_features_all.csv\n"
     ]
    }
   ],
   "source": [
    "# ——— DataFrame & CSV 저장 ———\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "out_dir = 'output'\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "csv_path = os.path.join(out_dir, 'text_features_all.csv')\n",
    "df.to_csv(csv_path, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(f'✅ 모든 세션 처리 완료, CSV → {csv_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a914183-3d8f-447a-897c-94e0f1df959a",
   "metadata": {},
   "source": [
    "#### 데이터셋 제작 새 코드 (샘플로 5개 시행)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "53ea7f4e-45ca-4642-bc29-c5269c9160aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bce28ffb7f504709989fe45950e9a9b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "샘플 5개 처리:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d6f0071cf4e41558f7407dc0e1f01be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "고객 감정분석:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfc901c50def4296bfdf556e13afcb0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "상담사 감정분석:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1c412aa7acf4cbe8eb191a8a0a83583",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "고객 감정분석:   0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "032b87a598f64f28836b5bdf0313d98f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "상담사 감정분석:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41cce9e4e8ec4e22a8af242f32fd6999",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "고객 감정분석:   0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d221426ca61044048f15a7a3c5dfec17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "상담사 감정분석:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6c3cf03a77742909e886f8efbc52516",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "고객 감정분석:   0%|          | 0/34 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c424d5e2d1d44656ac7ec91549c21507",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "상담사 감정분석:   0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1b7ff8fdd5748ff908426f14d893edd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "고객 감정분석:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2696dbb4dc214158aeceb33c601d2064",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "상담사 감정분석:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 샘플 특성추출 완료 → coloumns_extracion/sample/text_features_sample.csv\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import os, glob, json, re\n",
    "from collections import Counter, defaultdict\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "from konlpy.tag import Okt\n",
    "from transformers import pipeline\n",
    "\n",
    "# ——— 설정 ———\n",
    "okt = Okt()\n",
    "sentiment = pipeline(\n",
    "    'sentiment-analysis',\n",
    "    model='nlptown/bert-base-multilingual-uncased-sentiment',\n",
    "    top_k=None\n",
    ")\n",
    "\n",
    "# 키워드 사전 (예시)\n",
    "script_phrases       = [\"안녕하세요\", \"감사합니다\", \"반갑습니다\"]\n",
    "honorific_endings    = [\"습니다\", \"세요\", \"니다\"]\n",
    "positive_words       = [\"좋다\", \"만족\", \"행복\", \"감사\"]\n",
    "euphonious_words     = [\"해주\", \"드리\"]\n",
    "confirmation_phrases = [\"확인\", \"맞으신\", \"괜찮을까요\"]\n",
    "empathy_phrases      = [\"이해합니다\", \"공감\"]\n",
    "apology_phrases      = [\"죄송\", \"미안\"]\n",
    "request_phrases      = [\"부탁\", \"요청\"]\n",
    "alternative_phrases  = [\"하실 수 있습니다\", \"제안합니다\", \"추천드립니다\"]\n",
    "conflict_words       = [\"아닙니다\", \"불가\", \"불편\"]\n",
    "prohibit_words       = [\"욕설1\", \"욕설2\"]\n",
    "\n",
    "# ——— 문장 분리 유틸 ———\n",
    "def split_sentences(text):\n",
    "    return re.split(r'(?<=[\\.!\\?])\\s+', text)\n",
    "\n",
    "# ——— 화자별 감정분석 함수 ———\n",
    "def calc_speaker_emotion(content, speaker_tag):\n",
    "    lines = [\n",
    "        line[len(speaker_tag)+1:].strip()\n",
    "        for line in content.split('\\n')\n",
    "        if line.startswith(f'{speaker_tag}:')\n",
    "    ]\n",
    "    sents = []\n",
    "    for ln in lines:\n",
    "        for sent in split_sentences(ln):\n",
    "            if sent.strip():\n",
    "                sents.append(sent)\n",
    "    agg = defaultdict(float)\n",
    "    for sent in tqdm(sents, desc=f'{speaker_tag} 감정분석', leave=False):\n",
    "        scores = sentiment(sent)[0]\n",
    "        for d in scores:\n",
    "            star = int(d['label'][0])\n",
    "            agg[star] += d['score']\n",
    "    n = len(sents) or 1\n",
    "    star_scores = {f'{speaker_tag}_emo_{i}_star_score': agg[i]/n for i in range(1,6)}\n",
    "    sent_score = sum(i * star_scores[f'{speaker_tag}_emo_{i}_star_score'] for i in range(1,6))\n",
    "    if   sent_score >= 3.5: label = \"긍정\"\n",
    "    elif sent_score >= 2.5: label = \"중립\"\n",
    "    else:                  label = \"부정\"\n",
    "    star_scores[f'{speaker_tag}_sent_score'] = sent_score\n",
    "    star_scores[f'{speaker_tag}_sent_label'] = label\n",
    "    return star_scores\n",
    "\n",
    "# ——— 세션 특성추출 함수 ———\n",
    "def extract_text_features(record):\n",
    "    content = record['consulting_content']\n",
    "    sid = record['session_id']\n",
    "\n",
    "    # 1) ASR 세그먼트 & speech_count\n",
    "    segments = []\n",
    "    for line in content.split('\\n'):\n",
    "        m = re.match(r'^(상담사|고객):\\s*(.+)', line)\n",
    "        if m:\n",
    "            segments.append({'speaker': m.group(1), 'text': m.group(2)})\n",
    "    speech_count = len(segments)\n",
    "\n",
    "    # 2) 상위 명사\n",
    "    all_nouns = []\n",
    "    for seg in segments:\n",
    "        all_nouns += okt.nouns(seg['text'])\n",
    "    top_nouns = [w for w,_ in Counter(all_nouns).most_common(10)]\n",
    "\n",
    "    # 3) 세션 전체 감정 (문장별 평균)\n",
    "    agg = Counter({i:0.0 for i in range(1,6)})\n",
    "    n_sents = 0\n",
    "    for sent in split_sentences(content):\n",
    "        if not sent.strip(): continue\n",
    "        scores = sentiment(sent)[0]\n",
    "        for d in scores:\n",
    "            star = int(d['label'][0])\n",
    "            agg[star] += d['score']\n",
    "        n_sents += 1\n",
    "    emo = {f'emo_{i}_star_score': (agg[i]/n_sents if n_sents else 0.0) for i in range(1,6)}\n",
    "    sent_score = sum(i * emo[f'emo_{i}_star_score'] for i in range(1,6))\n",
    "    if   sent_score >= 3.5: sent_label = \"긍정\"\n",
    "    elif sent_score >= 2.5: sent_label = \"중립\"\n",
    "    else:                  sent_label = \"부정\"\n",
    "\n",
    "    # 4) 지시문(instructions)에서 분류 메타\n",
    "    mid_cat = None\n",
    "    cont_cat = None\n",
    "    for inst in record.get('instructions', []):\n",
    "        for d in inst.get('data', [inst]):\n",
    "            if d.get('task_category') == '상담 주제':\n",
    "                mid_cat = d.get('output')\n",
    "            elif d.get('task_category') == '상담 내용':\n",
    "                cont_cat = d.get('output')\n",
    "\n",
    "    # 5) 비율/카운트 헬퍼\n",
    "    def ratio(keys):\n",
    "        tot = len(content.split())\n",
    "        return sum(content.count(k) for k in keys) / tot if tot else 0\n",
    "    def count(keys):\n",
    "        return sum(content.count(k) for k in keys)\n",
    "\n",
    "    # ——— 기본 피처\n",
    "    feats = {\n",
    "        'session_id':                  sid,\n",
    "        'speech_count':                speech_count,\n",
    "        'top_nouns':                   ','.join(top_nouns),\n",
    "        **emo,\n",
    "        'sent_score':                  sent_score,\n",
    "        'sent_label':                  sent_label,\n",
    "        'mid_category':                mid_cat,\n",
    "        'content_category':            cont_cat,\n",
    "        'script_phrase_ratio':         ratio(script_phrases),\n",
    "        'honorific_ratio':             ratio(honorific_endings),\n",
    "        'positive_word_ratio':         ratio(positive_words),\n",
    "        'euphonious_word_ratio':       ratio(euphonious_words),\n",
    "        'confirmation_ratio':          ratio(confirmation_phrases),\n",
    "        'empathy_ratio':               ratio(empathy_phrases),\n",
    "        'apology_ratio':               ratio(apology_phrases),\n",
    "        'request_ratio':               ratio(request_phrases),\n",
    "        'alternative_suggestion_count':count(alternative_phrases),\n",
    "        'conflict_flag':               int(any(w in content for w in conflict_words)),\n",
    "        'manual_compliance_ratio':     1 - (count(prohibit_words)/max(1, speech_count))\n",
    "    }\n",
    "\n",
    "    # 6) 고객/상담사별 감정 추가\n",
    "    feats.update(calc_speaker_emotion(content, '고객'))\n",
    "    feats.update(calc_speaker_emotion(content, '상담사'))\n",
    "\n",
    "    return feats\n",
    "\n",
    "# ——— 실행 예시: 샘플 5개 추출 및 저장 ———\n",
    "files = glob.glob('json_merge/integration_data_v3/final_merged_*.json')[:5]\n",
    "rows = []\n",
    "for fp in tqdm(files, desc='샘플 5개 처리'):\n",
    "    rec = json.load(open(fp, 'r', encoding='utf-8'))\n",
    "    rec['consulting_content'] = rec.get('consulting_content') or rec.get('classification',{}).get('consulting_content','')\n",
    "    rec['instructions'] = rec.get('instructions', [])\n",
    "    rows.append(extract_text_features(rec))\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "os.makedirs('coloumns_extracion/sample', exist_ok=True)\n",
    "df.to_csv('coloumns_extracion/sample/text_features_sample.csv', index=False, encoding='utf-8-sig')\n",
    "print(\"✅ 샘플 특성추출 완료 → coloumns_extracion/sample/text_features_sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a404c564-db62-4a3e-9a83-cdae23321a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5f8a7ee27544e1bab59376e46b746a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "전체 세션 처리:   0%|          | 0/3533 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56d43af4834346c494b167018c8837d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "고객 감정분석:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a133e9a31264e0189ae778273282f6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "상담사 감정분석:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "963a94d6955144d0ba2feb89e8d81210",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "고객 감정분석:   0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc8a54955deb40f3b5d0671653bc6616",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "상담사 감정분석:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1b8cddc51624f98ab42094ddd15a027",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "고객 감정분석:   0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97903b2962cb4b2b8b6d386529501502",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "상담사 감정분석:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e46b72b5839449283be87cbcbd33631",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "고객 감정분석:   0%|          | 0/34 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "754a9322bb57406491740ee14b5fe4af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "상담사 감정분석:   0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a467c24502f4e74acdaa3de5ac1b476",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "고객 감정분석:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cb6b2a59fc7477d86f2def9077e6666",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "상담사 감정분석:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74052b4396bf4d7d939d10c7b712b576",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "고객 감정분석:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47cf857a3363411ea777c9001831f94d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "상담사 감정분석:   0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2da7f5ed5e5844cc96ad0b6302d1e0e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "고객 감정분석:   0%|          | 0/26 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97bedf491b524bb9b362f0ae5940e85c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "상담사 감정분석:   0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb5c6b22be7d4ad89b892561718d465c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "고객 감정분석:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a460e0b283644aa58157b0a39864d09a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "상담사 감정분석:   0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e002e3e1f3948a496a1896133712811",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "고객 감정분석:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ca1b1bef31d4d80810340d77651f2af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "상담사 감정분석:   0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22f999502e1647e09c56ce15b6ae86bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "고객 감정분석:   0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85f94643247c4c8fa755569d5860078b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "상담사 감정분석:   0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cef9f66618749c386268b8def712633",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "고객 감정분석:   0%|          | 0/29 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07ef9b0584de4c89baf2806319fe15b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "상담사 감정분석:   0%|          | 0/43 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d25456f20264bbf925fd21ec137b1c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "고객 감정분석:   0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2610aeb29e3e43198c33e1b14969069a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "상담사 감정분석:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6fa843b4b9648d89ec4a87eed771bf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "고객 감정분석:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e459d16f844345679888ca9f037f61d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "상담사 감정분석:   0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96629c56dba64164be9cda5f92a50fc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "고객 감정분석:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "002b722aa67b42ba9edf72e1386f2d2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "상담사 감정분석:   0%|          | 0/26 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2b46695685340019167d4817bbd9f31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "고객 감정분석:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 152\u001b[39m\n\u001b[32m    149\u001b[39m     rec[\u001b[33m'\u001b[39m\u001b[33mconsulting_content\u001b[39m\u001b[33m'\u001b[39m] = rec.get(\u001b[33m'\u001b[39m\u001b[33mconsulting_content\u001b[39m\u001b[33m'\u001b[39m) \\\n\u001b[32m    150\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m rec.get(\u001b[33m'\u001b[39m\u001b[33mclassification\u001b[39m\u001b[33m'\u001b[39m,{}).get(\u001b[33m'\u001b[39m\u001b[33mconsulting_content\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    151\u001b[39m     rec[\u001b[33m'\u001b[39m\u001b[33minstructions\u001b[39m\u001b[33m'\u001b[39m] = rec.get(\u001b[33m'\u001b[39m\u001b[33minstructions\u001b[39m\u001b[33m'\u001b[39m, [])\n\u001b[32m--> \u001b[39m\u001b[32m152\u001b[39m     rows.append(extract_text_features(rec))\n\u001b[32m    154\u001b[39m \u001b[38;5;66;03m# ——— DataFrame 생성 및 CSV 저장 ———\u001b[39;00m\n\u001b[32m    155\u001b[39m df = pd.DataFrame(rows)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 138\u001b[39m, in \u001b[36mextract_text_features\u001b[39m\u001b[34m(record)\u001b[39m\n\u001b[32m    115\u001b[39m feats = {\n\u001b[32m    116\u001b[39m     \u001b[33m'\u001b[39m\u001b[33msession_id\u001b[39m\u001b[33m'\u001b[39m:                  sid,\n\u001b[32m    117\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mspeech_count\u001b[39m\u001b[33m'\u001b[39m:                speech_count,\n\u001b[32m   (...)\u001b[39m\u001b[32m    134\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mmanual_compliance_ratio\u001b[39m\u001b[33m'\u001b[39m:     \u001b[32m1\u001b[39m - (count(prohibit_words)/\u001b[38;5;28mmax\u001b[39m(\u001b[32m1\u001b[39m, speech_count))\n\u001b[32m    135\u001b[39m }\n\u001b[32m    137\u001b[39m \u001b[38;5;66;03m# 6) 고객/상담사별 감정 추가\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m138\u001b[39m feats.update(calc_speaker_emotion(content, \u001b[33m'\u001b[39m\u001b[33m고객\u001b[39m\u001b[33m'\u001b[39m))\n\u001b[32m    139\u001b[39m feats.update(calc_speaker_emotion(content, \u001b[33m'\u001b[39m\u001b[33m상담사\u001b[39m\u001b[33m'\u001b[39m))\n\u001b[32m    141\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m feats\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 48\u001b[39m, in \u001b[36mcalc_speaker_emotion\u001b[39m\u001b[34m(content, speaker_tag)\u001b[39m\n\u001b[32m     46\u001b[39m agg = defaultdict(\u001b[38;5;28mfloat\u001b[39m)\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m sent \u001b[38;5;129;01min\u001b[39;00m tqdm(sents, desc=\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mspeaker_tag\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m 감정분석\u001b[39m\u001b[33m'\u001b[39m, leave=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m     scores = sentiment(sent)[\u001b[32m0\u001b[39m]\n\u001b[32m     49\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m scores:\n\u001b[32m     50\u001b[39m         star = \u001b[38;5;28mint\u001b[39m(d[\u001b[33m'\u001b[39m\u001b[33mlabel\u001b[39m\u001b[33m'\u001b[39m][\u001b[32m0\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/lib/python3.11/site-packages/transformers/pipelines/text_classification.py:159\u001b[39m, in \u001b[36mTextClassificationPipeline.__call__\u001b[39m\u001b[34m(self, inputs, **kwargs)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    125\u001b[39m \u001b[33;03mClassify the text(s) given as inputs.\u001b[39;00m\n\u001b[32m    126\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    156\u001b[39m \u001b[33;03m    If `top_k` is used, one such dictionary is returned per label.\u001b[39;00m\n\u001b[32m    157\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    158\u001b[39m inputs = (inputs,)\n\u001b[32m--> \u001b[39m\u001b[32m159\u001b[39m result = \u001b[38;5;28msuper\u001b[39m().\u001b[34m__call__\u001b[39m(*inputs, **kwargs)\n\u001b[32m    160\u001b[39m \u001b[38;5;66;03m# TODO try and retrieve it in a nicer way from _sanitize_parameters.\u001b[39;00m\n\u001b[32m    161\u001b[39m _legacy = \u001b[33m\"\u001b[39m\u001b[33mtop_k\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/lib/python3.11/site-packages/transformers/pipelines/base.py:1379\u001b[39m, in \u001b[36mPipeline.__call__\u001b[39m\u001b[34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[39m\n\u001b[32m   1371\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\n\u001b[32m   1372\u001b[39m         \u001b[38;5;28miter\u001b[39m(\n\u001b[32m   1373\u001b[39m             \u001b[38;5;28mself\u001b[39m.get_iterator(\n\u001b[32m   (...)\u001b[39m\u001b[32m   1376\u001b[39m         )\n\u001b[32m   1377\u001b[39m     )\n\u001b[32m   1378\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1379\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.run_single(inputs, preprocess_params, forward_params, postprocess_params)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/lib/python3.11/site-packages/transformers/pipelines/base.py:1386\u001b[39m, in \u001b[36mPipeline.run_single\u001b[39m\u001b[34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[39m\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34mrun_single\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, preprocess_params, forward_params, postprocess_params):\n\u001b[32m   1385\u001b[39m     model_inputs = \u001b[38;5;28mself\u001b[39m.preprocess(inputs, **preprocess_params)\n\u001b[32m-> \u001b[39m\u001b[32m1386\u001b[39m     model_outputs = \u001b[38;5;28mself\u001b[39m.forward(model_inputs, **forward_params)\n\u001b[32m   1387\u001b[39m     outputs = \u001b[38;5;28mself\u001b[39m.postprocess(model_outputs, **postprocess_params)\n\u001b[32m   1388\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/lib/python3.11/site-packages/transformers/pipelines/base.py:1286\u001b[39m, in \u001b[36mPipeline.forward\u001b[39m\u001b[34m(self, model_inputs, **forward_params)\u001b[39m\n\u001b[32m   1284\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[32m   1285\u001b[39m         model_inputs = \u001b[38;5;28mself\u001b[39m._ensure_tensor_on_device(model_inputs, device=\u001b[38;5;28mself\u001b[39m.device)\n\u001b[32m-> \u001b[39m\u001b[32m1286\u001b[39m         model_outputs = \u001b[38;5;28mself\u001b[39m._forward(model_inputs, **forward_params)\n\u001b[32m   1287\u001b[39m         model_outputs = \u001b[38;5;28mself\u001b[39m._ensure_tensor_on_device(model_outputs, device=torch.device(\u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m   1288\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/lib/python3.11/site-packages/transformers/pipelines/text_classification.py:190\u001b[39m, in \u001b[36mTextClassificationPipeline._forward\u001b[39m\u001b[34m(self, model_inputs)\u001b[39m\n\u001b[32m    188\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33muse_cache\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m inspect.signature(model_forward).parameters.keys():\n\u001b[32m    189\u001b[39m     model_inputs[\u001b[33m\"\u001b[39m\u001b[33muse_cache\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m190\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.model(**model_inputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_impl(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(*args, **kwargs)\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:1675\u001b[39m, in \u001b[36mBertForSequenceClassification.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m   1667\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1668\u001b[39m \u001b[33;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[32m   1669\u001b[39m \u001b[33;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[32m   1670\u001b[39m \u001b[33;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[32m   1671\u001b[39m \u001b[33;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[32m   1672\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1673\u001b[39m return_dict = return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config.use_return_dict\n\u001b[32m-> \u001b[39m\u001b[32m1675\u001b[39m outputs = \u001b[38;5;28mself\u001b[39m.bert(\n\u001b[32m   1676\u001b[39m     input_ids,\n\u001b[32m   1677\u001b[39m     attention_mask=attention_mask,\n\u001b[32m   1678\u001b[39m     token_type_ids=token_type_ids,\n\u001b[32m   1679\u001b[39m     position_ids=position_ids,\n\u001b[32m   1680\u001b[39m     head_mask=head_mask,\n\u001b[32m   1681\u001b[39m     inputs_embeds=inputs_embeds,\n\u001b[32m   1682\u001b[39m     output_attentions=output_attentions,\n\u001b[32m   1683\u001b[39m     output_hidden_states=output_hidden_states,\n\u001b[32m   1684\u001b[39m     return_dict=return_dict,\n\u001b[32m   1685\u001b[39m )\n\u001b[32m   1687\u001b[39m pooled_output = outputs[\u001b[32m1\u001b[39m]\n\u001b[32m   1689\u001b[39m pooled_output = \u001b[38;5;28mself\u001b[39m.dropout(pooled_output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_impl(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(*args, **kwargs)\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:1120\u001b[39m, in \u001b[36mBertModel.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m   1116\u001b[39m     extended_attention_mask = \u001b[38;5;28mself\u001b[39m.get_extended_attention_mask(attention_mask, input_shape)\n\u001b[32m   1118\u001b[39m \u001b[38;5;66;03m# If a 2D or 3D attention mask is provided for the cross-attention\u001b[39;00m\n\u001b[32m   1119\u001b[39m \u001b[38;5;66;03m# we need to make broadcastable to [batch_size, num_heads, seq_length, seq_length]\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1120\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config.is_decoder \u001b[38;5;129;01mand\u001b[39;00m encoder_hidden_states \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1121\u001b[39m     encoder_batch_size, encoder_sequence_length, _ = encoder_hidden_states.size()\n\u001b[32m   1122\u001b[39m     encoder_hidden_shape = (encoder_batch_size, encoder_sequence_length)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/lib/python3.11/site-packages/transformers/configuration_utils.py:207\u001b[39m, in \u001b[36mPretrainedConfig.__getattribute__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m    204\u001b[39m         key = \u001b[38;5;28msuper\u001b[39m().\u001b[34m__getattribute__\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mattribute_map\u001b[39m\u001b[33m\"\u001b[39m)[key]\n\u001b[32m    205\u001b[39m     \u001b[38;5;28msuper\u001b[39m().\u001b[34m__setattr__\u001b[39m(key, value)\n\u001b[32m--> \u001b[39m\u001b[32m207\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34m__getattribute__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[32m    208\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m key != \u001b[33m\"\u001b[39m\u001b[33mattribute_map\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__getattribute__\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mattribute_map\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    209\u001b[39m         key = \u001b[38;5;28msuper\u001b[39m().\u001b[34m__getattribute__\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mattribute_map\u001b[39m\u001b[33m\"\u001b[39m)[key]\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import os, glob, json, re\n",
    "from collections import Counter, defaultdict\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "from konlpy.tag import Okt\n",
    "from transformers import pipeline\n",
    "\n",
    "# ——— 설정 ———\n",
    "okt = Okt()\n",
    "sentiment = pipeline(\n",
    "    'sentiment-analysis',\n",
    "    model='nlptown/bert-base-multilingual-uncased-sentiment',\n",
    "    top_k=None\n",
    ")\n",
    "\n",
    "# 키워드 사전 (예시)\n",
    "script_phrases       = [\"안녕하세요\", \"감사합니다\", \"반갑습니다\"]\n",
    "honorific_endings    = [\"습니다\", \"세요\", \"니다\"]\n",
    "positive_words       = [\"좋다\", \"만족\", \"행복\", \"감사\"]\n",
    "euphonious_words     = [\"해주\", \"드리\"]\n",
    "confirmation_phrases = [\"확인\", \"맞으신\", \"괜찮을까요\"]\n",
    "empathy_phrases      = [\"이해합니다\", \"공감\"]\n",
    "apology_phrases      = [\"죄송\", \"미안\"]\n",
    "request_phrases      = [\"부탁\", \"요청\"]\n",
    "alternative_phrases  = [\"하실 수 있습니다\", \"제안합니다\", \"추천드립니다\"]\n",
    "conflict_words       = [\"아닙니다\", \"불가\", \"불편\"]\n",
    "prohibit_words       = [\"욕설1\", \"욕설2\"]\n",
    "\n",
    "# ——— 문장 분리 유틸 ———\n",
    "def split_sentences(text):\n",
    "    return re.split(r'(?<=[\\.!\\?])\\s+', text)\n",
    "\n",
    "# ——— 화자별 감정분석 함수 ———\n",
    "def calc_speaker_emotion(content, speaker_tag):\n",
    "    lines = [\n",
    "        line[len(speaker_tag)+1:].strip()\n",
    "        for line in content.split('\\n')\n",
    "        if line.startswith(f'{speaker_tag}:')\n",
    "    ]\n",
    "    sents = []\n",
    "    for ln in lines:\n",
    "        for sent in split_sentences(ln):\n",
    "            if sent.strip():\n",
    "                sents.append(sent)\n",
    "    agg = defaultdict(float)\n",
    "    for sent in tqdm(sents, desc=f'{speaker_tag} 감정분석', leave=False):\n",
    "        scores = sentiment(sent)[0]\n",
    "        for d in scores:\n",
    "            star = int(d['label'][0])\n",
    "            agg[star] += d['score']\n",
    "    n = len(sents) or 1\n",
    "    star_scores = {f'{speaker_tag}_emo_{i}_star_score': agg[i]/n for i in range(1,6)}\n",
    "    sent_score = sum(i * star_scores[f'{speaker_tag}_emo_{i}_star_score'] for i in range(1,6))\n",
    "    if   sent_score >= 3.5: label = \"긍정\"\n",
    "    elif sent_score >= 2.5: label = \"중립\"\n",
    "    else:                  label = \"부정\"\n",
    "    star_scores[f'{speaker_tag}_sent_score'] = sent_score\n",
    "    star_scores[f'{speaker_tag}_sent_label'] = label\n",
    "    return star_scores\n",
    "\n",
    "# ——— 세션 특성추출 함수 ———\n",
    "def extract_text_features(record):\n",
    "    content = record['consulting_content']\n",
    "    sid = record['session_id']\n",
    "\n",
    "    # 1) ASR 세그먼트 & speech_count\n",
    "    segments = []\n",
    "    for line in content.split('\\n'):\n",
    "        m = re.match(r'^(상담사|고객):\\s*(.+)', line)\n",
    "        if m:\n",
    "            segments.append({'speaker': m.group(1), 'text': m.group(2)})\n",
    "    speech_count = len(segments)\n",
    "\n",
    "    # 2) 상위 명사\n",
    "    all_nouns = []\n",
    "    for seg in segments:\n",
    "        all_nouns += okt.nouns(seg['text'])\n",
    "    top_nouns = [w for w,_ in Counter(all_nouns).most_common(10)]\n",
    "\n",
    "    # 3) 세션 전체 감정 (문장별 평균)\n",
    "    agg = Counter({i:0.0 for i in range(1,6)})\n",
    "    n_sents = 0\n",
    "    for sent in split_sentences(content):\n",
    "        if not sent.strip(): continue\n",
    "        scores = sentiment(sent)[0]\n",
    "        for d in scores:\n",
    "            star = int(d['label'][0])\n",
    "            agg[star] += d['score']\n",
    "        n_sents += 1\n",
    "    emo = {f'emo_{i}_star_score': (agg[i]/n_sents if n_sents else 0.0) for i in range(1,6)}\n",
    "    sent_score = sum(i * emo[f'emo_{i}_star_score'] for i in range(1,6))\n",
    "    if   sent_score >= 3.5: sent_label = \"긍정\"\n",
    "    elif sent_score >= 2.5: sent_label = \"중립\"\n",
    "    else:                  sent_label = \"부정\"\n",
    "\n",
    "    # 4) 지시문(instructions)에서 분류 메타\n",
    "    mid_cat = None\n",
    "    cont_cat = None\n",
    "    for inst in record.get('instructions', []):\n",
    "        for d in inst.get('data', [inst]):\n",
    "            if d.get('task_category') == '상담 주제':\n",
    "                mid_cat = d.get('output')\n",
    "            elif d.get('task_category') == '상담 내용':\n",
    "                cont_cat = d.get('output')\n",
    "\n",
    "    # 5) 비율/카운트 헬퍼\n",
    "    def ratio(keys):\n",
    "        tot = len(content.split())\n",
    "        return sum(content.count(k) for k in keys) / tot if tot else 0\n",
    "    def count(keys):\n",
    "        return sum(content.count(k) for k in keys)\n",
    "\n",
    "    # — 기본 피처\n",
    "    feats = {\n",
    "        'session_id':                  sid,\n",
    "        'speech_count':                speech_count,\n",
    "        'top_nouns':                   ','.join(top_nouns),\n",
    "        **emo,\n",
    "        'sent_score':                  sent_score,\n",
    "        'sent_label':                  sent_label,\n",
    "        'mid_category':                mid_cat,\n",
    "        'content_category':            cont_cat,\n",
    "        'script_phrase_ratio':         ratio(script_phrases),\n",
    "        'honorific_ratio':             ratio(honorific_endings),\n",
    "        'positive_word_ratio':         ratio(positive_words),\n",
    "        'euphonious_word_ratio':       ratio(euphonious_words),\n",
    "        'confirmation_ratio':          ratio(confirmation_phrases),\n",
    "        'empathy_ratio':               ratio(empathy_phrases),\n",
    "        'apology_ratio':               ratio(apology_phrases),\n",
    "        'request_ratio':               ratio(request_phrases),\n",
    "        'alternative_suggestion_count':count(alternative_phrases),\n",
    "        'conflict_flag':               int(any(w in content for w in conflict_words)),\n",
    "        'manual_compliance_ratio':     1 - (count(prohibit_words)/max(1, speech_count))\n",
    "    }\n",
    "\n",
    "    # 6) 고객/상담사별 감정 추가\n",
    "    feats.update(calc_speaker_emotion(content, '고객'))\n",
    "    feats.update(calc_speaker_emotion(content, '상담사'))\n",
    "\n",
    "    return feats\n",
    "\n",
    "# ——— 전체 JSON 파일 순회 & 처리 ———\n",
    "files = glob.glob('json_merge/integration_data_v3/final_merged_*.json')  # 전체 파일\n",
    "rows = []\n",
    "for fp in tqdm(files, desc='전체 세션 처리'):\n",
    "    rec = json.load(open(fp, 'r', encoding='utf-8'))\n",
    "    # consulting_content / instructions 필드 보정\n",
    "    rec['consulting_content'] = rec.get('consulting_content') \\\n",
    "        or rec.get('classification',{}).get('consulting_content','')\n",
    "    rec['instructions'] = rec.get('instructions', [])\n",
    "    rows.append(extract_text_features(rec))\n",
    "\n",
    "# ——— DataFrame 생성 및 CSV 저장 ———\n",
    "df = pd.DataFrame(rows)\n",
    "os.makedirs('columns_extraction/all', exist_ok=True)\n",
    "df.to_csv(\n",
    "    'columns_extraction/all/text_features_all_v3.csv',\n",
    "    index=False, encoding='utf-8-sig'\n",
    ")\n",
    "print(\"✅ 전체 특성추출 완료 → columns_extraction/all/text_features_all_v3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076bb655-76ef-47a1-b5e8-003a2a562ab8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
